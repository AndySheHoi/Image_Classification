{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "digits_classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOk7HNBjmw_v",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://adeshpande3.github.io/assets/Cover.png)\n",
        "# *Reference*ï¼š https://www.tensorflow.org/tutorials/quickstart/advanced\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hk3YsX-hG9tU",
        "colab_type": "text"
      },
      "source": [
        "# **Import Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95eOzvK2F3wR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgIBrW8xHPpf",
        "colab_type": "text"
      },
      "source": [
        "# **Load the dataset and split it**<br>\n",
        "There are 60,000 images in the training set, 10,000 images in the test set<br> Each image is represented as 28 x 28 pixels<br>\n",
        "x_train.shape = (60000, 28, 28)<br>\n",
        "x_test.shape = (10000, 28, 28)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRgfoqDGHRHb",
        "colab_type": "code",
        "outputId": "b35d4085-5570-4fca-c223-381cc72c4be2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "dataset = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = dataset.load_data()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUzQvXL7IB5o",
        "colab_type": "text"
      },
      "source": [
        "Pixel values are 0 to 255. 0 means background (white), 255 means foreground (black).<br>\n",
        "Normalize the data, turn the integers in x_train and x_test into floating points between 0-1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCv8tOxRJMKE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_test = x_train/255.0, x_test/255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSMhmQBxkTjY",
        "colab_type": "text"
      },
      "source": [
        "The Shape of an Image Tensor: [Sample, length, width, Channel]<br>\n",
        "Sample : number of images<br>\n",
        "Channel: number of color channels<br>\n",
        "Since the gray-scale picture is read here, the number of color channels is 1 (the number of color channels of a color RGB image is 3)<br>\n",
        "x_train.shape = (60000, 28, 28, 1)<br>\n",
        "x_test.shape = (10000, 28, 28, 1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_k_ZTUGjSdB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train[..., tf.newaxis]  \n",
        "x_test = x_test[..., tf.newaxis]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWh6Nuuv1UOX",
        "colab_type": "text"
      },
      "source": [
        "# **Data preprocessing: shuffle the dataset and batch**\n",
        "tf.data.Dataset.from_tensor_slices(), suitable for the case where the amount of data is small (it can be loaded into memory as a whole)<br>\n",
        "When providing multiple tensors as input, the 0th dimension of tensors must be the same, and multiple tensors must be used as tuples<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiWwtiwntZO5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(batch_size)\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsoTGa4t7fgH",
        "colab_type": "text"
      },
      "source": [
        "# **Build the model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "y2uWqbT_hq5u"
      },
      "source": [
        "# **Zero Padding**<br> \n",
        "With Zero Padding, the convolution layer is the same size as the original\n",
        "image (or the previous layer).<br>\n",
        "Kernel size (Receptive field): [4, 4]<br>\n",
        "![alt text](https://xrds.acm.org/blog/wp-content/uploads/2016/06/Figure_3.png)\n",
        "\n",
        "# **Max Pooling**<br> \n",
        "MaxPooling is the process of downsampling the image. For all values in each sliding window, the maximum value is output.\n",
        "![alt text](https://cdn-images-1.medium.com/freeze/max/1000/1*GksqN5XY8HPpIddm5wzm7A.jpeg?q=20)\n",
        "\n",
        "# **Activation functions**<br>\n",
        "The activation function is to increase the nonlinearity of the neural network model. Each layer without an activation function is equivalent to matrix multiplication\n",
        "\n",
        "# **Why ReLU?**\n",
        "1.   When using functions such as sigmoid, the calculation amount is large, and using the Relu activation function, the calculation amount is saved a lot.\n",
        "2.   For deep networks, when the sigmoid function is back-propagated, it is easy for the gradient to disappear (when the sigmoid is close to the saturation region, the transformation is too slow, the derivative tends to 0, this situation will cause information loss), and the deep layer cannot be completed Network training.\n",
        "3.   Relu will make the output of some neurons to 0, which causes the sparsity of the network, and reduces the interdependence of parameters, alleviating the occurrence of overfitting problems.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "![alt text](https://miro.medium.com/max/1192/1*4ZEDRpFuCIpUjNgjDdT2Lg.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CC5ZxUub7c4H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNN(Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = Conv2D(\n",
        "            filters=64,     # Number of convolutional neurons (convolution kernel)      \n",
        "            kernel_size=[5, 5], # Receptive Field    \n",
        "            padding='same',   # zero padding    \n",
        "            activation=tf.nn.relu   \n",
        "        )\n",
        "        self.max_pool1 = MaxPool2D(pool_size=[2, 2], strides=2)\n",
        "        self.conv2 = Conv2D(\n",
        "            filters=128,\n",
        "            kernel_size=[5, 5],\n",
        "            padding='same',\n",
        "            activation=tf.nn.relu\n",
        "        )\n",
        "        self.max_pool2 = MaxPool2D(pool_size=[2, 2], strides=2)\n",
        "        self.flatten = Flatten()\n",
        "        self.dense1 = Dense(units=1024, activation=tf.nn.relu)\n",
        "        self.dropout = Dropout(rate = 0.5) # prevent overfitting\n",
        "        self.dense2 = Dense(units=10)\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        x = self.conv1(inputs)    # [batch_size, 28, 28, 32]\n",
        "        x = self.max_pool1(x)     # [batch_size, 14, 14, 32]\n",
        "        x = self.conv2(x)       # [batch_size, 14, 14, 64]\n",
        "        x = self.max_pool2(x)     # [batch_size, 7, 7, 64]\n",
        "        x = self.flatten(x)      # [batch_size, 7 * 7 * 64]\n",
        "        x = self.dense1(x)      # [batch_size, 1024] \n",
        "        if(training == True):\n",
        "            x = self.dropout(x)  # [batch_size, 1024]\n",
        "        x = self.dense2(x)      # [batch_size, 10], 10 represents the probability that this picture belongs to 0 to 9\n",
        "        output = tf.nn.softmax(x)  # After using softmax, each element in this vector is between [0, 1] and the sum of all elements of this vector is 1\n",
        "        return output\n",
        "\n",
        "model = CNN()\n",
        "# model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-INqJN_lTiu8",
        "colab_type": "text"
      },
      "source": [
        "# **Train and test the model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmSsOhQqsLEP",
        "colab_type": "text"
      },
      "source": [
        "tf.keras.losses.SparseCategoricalCrossentropy(): the closer the predicted probability distribution and the true distribution are, the smaller the value of cross-entropy and vice versa (the function expects labels to be provided as integers)<br>\n",
        "Note: Using from_logits=True may be more numerically stable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-g3lEHeLTUXG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "learning_rate = 0.001\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Okvy4QsBulmG",
        "colab_type": "text"
      },
      "source": [
        "tf.keras.metrics.SparseCategoricalAccuracy(): compare the predicted results of the model with the real results, and output the ratio of the number of samples predicted correctly to the total number of samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o27y03_ZTVv3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
        "\n",
        "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_gvhL2NyRbP",
        "colab_type": "text"
      },
      "source": [
        "tf.GradientTape() can record the calculation steps and operations in its context and be used for automatic derivation\n",
        "1.   Use tape.gradient() to automatically calculate the gradient\n",
        "2.   Use optimizer.apply_gradients() to automatically update model parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8wbUjk_TYia",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(images, labels):\n",
        "    with tf.GradientTape() as tape:\n",
        "    # training=True is only needed if there are layers with different\n",
        "    # behavior during training versus inference (e.g. Dropout).\n",
        "        predictions = model(images, training=True)\n",
        "        loss = loss_object(labels, predictions)\n",
        "\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    \n",
        "    train_loss(loss)\n",
        "    train_accuracy(labels, predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjigykONTmUj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def test_step(images, labels):\n",
        "    # training=False is only needed if there are layers with different\n",
        "    # behavior during training versus inference (e.g. Dropout).\n",
        "    predictions = model(images, training=False)\n",
        "    loss = loss_object(labels, predictions)\n",
        "\n",
        "    test_loss(loss)\n",
        "    test_accuracy(labels, predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXx6O2itTvto",
        "colab_type": "code",
        "outputId": "f59f3702-2316-472f-f880-ca8d90e2f780",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "num_epoch = 5\n",
        "\n",
        "for epoch in range(num_epoch):\n",
        "    # Reset the metrics at the start of the next epoch\n",
        "    train_loss.reset_states()\n",
        "    train_accuracy.reset_states()\n",
        "    test_loss.reset_states()\n",
        "    test_accuracy.reset_states()\n",
        "\n",
        "    for train_images, train_labels in train_ds:\n",
        "        train_step(train_images, train_labels)\n",
        "\n",
        "    for test_images, test_labels in test_ds:\n",
        "        test_step(test_images, test_labels)\n",
        "        \n",
        "    template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
        "    print(template.format(epoch+1, train_loss.result(), train_accuracy.result()*100, test_loss.result(), test_accuracy.result()*100))\n",
        "\n",
        "print('End')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer cnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "Epoch 1, Loss: 1.530685544013977, Accuracy: 93.25833129882812, Test Loss: 1.4822640419006348, Test Accuracy: 97.93999481201172\n",
            "Epoch 2, Loss: 1.4836128950119019, Accuracy: 97.79666900634766, Test Loss: 1.4737579822540283, Test Accuracy: 98.79000091552734\n",
            "Epoch 3, Loss: 1.47808039188385, Accuracy: 98.3316650390625, Test Loss: 1.4733924865722656, Test Accuracy: 98.77999877929688\n",
            "Epoch 4, Loss: 1.4762775897979736, Accuracy: 98.50833129882812, Test Loss: 1.4718986749649048, Test Accuracy: 98.94999694824219\n",
            "Epoch 5, Loss: 1.4743982553482056, Accuracy: 98.67666625976562, Test Loss: 1.4702008962631226, Test Accuracy: 99.0999984741211\n",
            "End\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}